episode:1, reward: -43.44682349712445, mean reward: -2.05, score: -237.88424261379393, epsilon: 0.8974901414056311, total steps: 208
episode:2, reward: -9.892732454959527, mean reward: -11.63, score: -209.26492303404854, epsilon: 0.89727224338593, total steps: 226
episode:3, reward: -49.668403654437824, mean reward: -1.7, score: -243.70946797092802, epsilon: 0.8955431539742411, total steps: 369
episode:4, reward: -7.358006650237505, mean reward: -4.21, score: -206.29852681885754, epsilon: 0.8949514808762035, total steps: 418
episode:5, reward: -11.270315186734747, mean reward: -11.27, score: -202.89184248193828, epsilon: 0.8947342355710002, total steps: 436
episode:6, reward: 3.9291785419081484, mean reward: -0.93, score: -195.1675877193791, epsilon: 0.8922158619391231, total steps: 645
episode:7, reward: -3.2226892749616733, mean reward: -3.96, score: -202.15673204948152, epsilon: 0.8916024710021133, total steps: 696
episode:8, reward: -5.280512044525564, mean reward: -3.42, score: -201.63585359165927, epsilon: 0.8908934192046455, total steps: 755
episode:9, reward: -10.519914590043797, mean reward: -1.45, score: -202.562089475231, epsilon: 0.8892133130324437, total steps: 895
episode:10, reward: -7.684178689336167, mean reward: -7.42, score: -200.3055587669177, epsilon: 0.8888896788880143, total steps: 922
episode:11, reward: -4.944526871557196, mean reward: -4.58, score: -201.30370852318117, epsilon: 0.8883625424929363, total steps: 966
episode:12, reward: -6.5740249769300405, mean reward: -6.75, score: -202.38544323379895, epsilon: 0.8880033212419199, total steps: 996
episode:13, reward: -9.574323262160158, mean reward: -5.3, score: -206.75674694837588, epsilon: 0.8875365637146131, total steps: 1035
episode:14, reward: -2.3346974564352916, mean reward: -1.87, score: -202.1217591170165, epsilon: 0.8862453607718559, total steps: 1143
episode:15, reward: -3.464279147901326, mean reward: -1.26, score: -203.37986810726434, epsilon: 0.8843242066162684, total steps: 1304
episode:16, reward: -11.605545949281908, mean reward: -1.73, score: -211.1306169973453, epsilon: 0.8828713651286473, total steps: 1426
episode:17, reward: -3.3080029873417383, mean reward: -1.03, score: -199.63709353670203, epsilon: 0.8805663172441751, total steps: 1620
episode:18, reward: -10.796658751491796, mean reward: -7.21, score: -201.95126641230456, epsilon: 0.8802341571537243, total steps: 1648
episode:19, reward: -8.42247911180899, mean reward: -8.43, score: -202.31178852472092, epsilon: 0.8799495542345599, total steps: 1672
episode:10, reward: -2.3746088276359565, mean reward: -1.17, score: -201.70364424772686, epsilon: 0.8853617970707105, total steps: 1217
episode:11, reward: -9.309630919848832, mean reward: -5.69, score: -204.93546381408373, epsilon: 0.8849322928856169, total steps: 1253
episode:12, reward: -4.909191057079293, mean reward: -3.71, score: -203.95683151712504, epsilon: 0.8842765323094549, total steps: 1308
episode:13, reward: -7.485323306872949, mean reward: -7.76, score: -201.87799379109597, epsilon: 0.8839667157098131, total steps: 1334
episode:14, reward: -8.475758723316876, mean reward: -5.2, score: -207.81045933597758, epsilon: 0.883490299432736, total steps: 1374
episode:15, reward: -2.978296850711646, mean reward: -3.87, score: -201.32307089182817, epsilon: 0.8828713651286473, total steps: 1426
episode:16, reward: -2.102053462046304, mean reward: -1.9, score: -201.43173538305393, epsilon: 0.8816111143492904, total steps: 1532
episode:17, reward: -14.227812617141101, mean reward: -10.57, score: -200.7727251479008, epsilon: 0.881385421963605, total steps: 1551
episode:18, reward: -11.04771811543261, mean reward: -7.09, score: -205.63336619043122, epsilon: 0.8810410621968114, total steps: 1580
episode:19, reward: -7.316868121606623, mean reward: -4.44, score: -204.3070072703358, epsilon: 0.8804951288965269, total steps: 1626
episode:20, reward: -100, mean reward: -6.85, score: -232.90337516400737, epsilon: 0.8800918434968742, total steps: 1660
episode:21, reward: -13.759071632682451, mean reward: -9.3, score: -204.55050799431675, epsilon: 0.8798309984809962, total steps: 1682
episode:22, reward: -10.603031610952439, mean reward: -2.09, score: -206.98683839876162, epsilon: 0.8786582098791405, total steps: 1781
episode:23, reward: -6.991968706767502, mean reward: -4.89, score: -205.31489451414384, epsilon: 0.8781611640818636, total steps: 1823
episode:24, reward: -9.324325650798261, mean reward: -5.88, score: -200.0538611117609, epsilon: 0.8777590120469957, total steps: 1857
episode:25, reward: -6.521308160645767, mean reward: -7.15, score: -200.29957574487403, epsilon: 0.8774279746540693, total steps: 1885
episode:26, reward: -3.5709660844078566, mean reward: -3.75, score: -202.73798610779306, epsilon: 0.8767899192123632, total steps: 1939
episode:27, reward: -6.132219993428895, mean reward: -9.8, score: -205.86602281642362, epsilon: 0.8765419194384255, total steps: 1960
episode:28, reward: -8.806824595655694, mean reward: -8.24, score: -206.05155509256193, epsilon: 0.8762467786026268, total steps: 1985
episode:29, reward: -6.394743416380383, mean reward: -2.35, score: -202.25573488301836, epsilon: 0.8752322987255858, total steps: 2071
episode:30, reward: -9.026386604930893, mean reward: -5.43, score: -206.31299423426526, epsilon: 0.8747844370511593, total steps: 2109
episode:31, reward: -6.99484974409259, mean reward: -7.63, score: -206.09497614423876, epsilon: 0.8744663672571289, total steps: 2136
episode:32, reward: -7.217028381064727, mean reward: -7.63, score: -205.99745269576152, epsilon: 0.8741484201235046, total steps: 2163
episode:33, reward: -5.239876362900045, mean reward: -1.21, score: -200.80282216062366, epsilon: 0.8721963265529875, total steps: 2329
episode:34, reward: -5.826767009805079, mean reward: -5.9, score: -200.50215522167062, epsilon: 0.871797071021426, total steps: 2363
episode:35, reward: -13.493672811088691, mean reward: -9.35, score: -205.7435191728041, epsilon: 0.871538832524423, total steps: 2385
episode:36, reward: -10.263422743144714, mean reward: -10.54, score: -200.21398308053801, epsilon: 0.8713158736728079, total steps: 2404
episode:37, reward: -9.588198932677011, mean reward: -6.58, score: -203.97028630202595, epsilon: 0.8709522285989625, total steps: 2435
episode:38, reward: -8.176304192207072, mean reward: -8.4, score: -201.60091766676243, epsilon: 0.8706708075098148, total steps: 2459
episode:39, reward: -1.8780881863202847, mean reward: -3.77, score: -200.05183433483413, epsilon: 0.8700496776415374, total steps: 2512
episode:40, reward: -5.352278965020087, mean reward: -4.84, score: -203.30907365868273, epsilon: 0.869557795414377, total steps: 2554
episode:41, reward: -2.4323812882429614, mean reward: -3.1, score: -201.3028161711575, epsilon: 0.8687971306819176, total steps: 2619
episode:42, reward: -2.051712036476858, mean reward: -1.49, score: -201.31123337286178, epsilon: 0.8672195436634845, total steps: 2754
episode:43, reward: -4.454967040198681, mean reward: -5.46, score: -202.17833258042523, epsilon: 0.8667876989022892, total steps: 2791
episode:44, reward: -9.336384356069306, mean reward: -6.02, score: -204.6486975814001, epsilon: 0.8663910697805497, total steps: 2825
episode:45, reward: -4.436488643845842, mean reward: -2.77, score: -202.25652737109493, epsilon: 0.8655401343012552, total steps: 2898
episode:46, reward: -10.53450440651631, mean reward: -6.5, score: -207.9972522250788, epsilon: 0.8651674011567846, total steps: 2930
episode:47, reward: -7.3092216121552696, mean reward: -6.87, score: -206.21727498194497, epsilon: 0.8648181185507648, total steps: 2960
episode:48, reward: -8.47652908941295, mean reward: -5.02, score: -200.6455638538675, epsilon: 0.8643526412035011, total steps: 3000
episode:49, reward: -10.937577230067543, mean reward: -6.8, score: -203.91720201703941, epsilon: 0.8640037077055043, total steps: 3030
episode:50, reward: -4.828895451398717, mean reward: -4.91, score: -201.3892861513127, epsilon: 0.8635270737045747, total steps: 3071
episode:51, reward: -5.474181565139826, mean reward: -6.19, score: -204.16998805080718, epsilon: 0.8631436441853162, total steps: 3104
episode:52, reward: 3.9287940560615695, mean reward: -0.57, score: -201.30532074326618, epsilon: 0.8590765150221157, total steps: 3455
episode:53, reward: -5.035710727341403, mean reward: -4.78, score: -200.55922785069146, epsilon: 0.8585912147177528, total steps: 3497
episode:54, reward: -4.280296955862251, mean reward: -5.36, score: -203.7308384612027, epsilon: 0.8581523843230755, total steps: 3535
episode:55, reward: -1.1838625362577464, mean reward: -1.76, score: -202.05445439797248, epsilon: 0.856825795402385, total steps: 3650
episode:56, reward: -10.397350825201197, mean reward: -10.57, score: -200.85173245551968, epsilon: 0.8566068295474862, total steps: 3669
episode:57, reward: -10.0995029392987, mean reward: -6.76, score: -209.52476257775024, epsilon: 0.8562496970367222, total steps: 3700
episode:58, reward: -4.214728000168537, mean reward: -4.38, score: -201.6714423015255, epsilon: 0.8557200498532327, total steps: 3746
episode:59, reward: -137.33043898726203, mean reward: -3.4, score: -217.79435989059823, epsilon: 0.8549837281774251, total steps: 3810
episode:60, reward: -38.42427409107996, mean reward: -1.39, score: -237.69182663049673, epsilon: 0.8530196678632659, total steps: 3981
episode:61, reward: -9.441418979402254, mean reward: -9.43, score: -207.36773413150885, epsilon: 0.8527673299085502, total steps: 4003
episode:62, reward: -3.508715170411168, mean reward: -7.14, score: -200.03953863648763, epsilon: 0.8524462871894112, total steps: 4031
episode:63, reward: -10.01612382476343, mean reward: -11.95, score: -203.07213017894, epsilon: 0.8522514310388698, total steps: 4048
episode:64, reward: -3.201475045347952, mean reward: -1.3, score: -202.26202212675634, epsilon: 0.850476982448956, total steps: 4203
episode:65, reward: -7.0980317771346515, mean reward: -7.64, score: -206.1636300286071, epsilon: 0.8501682865794704, total steps: 4230
episode:66, reward: -2.290998940832101, mean reward: -1.54, score: -203.38355677677785, epsilon: 0.8486608195832196, total steps: 4362
episode:67, reward: -3.6675821518553517, mean reward: -1.16, score: -201.9985603274219, epsilon: 0.8466780423043728, total steps: 4536
episode:68, reward: -2.447299343104882, mean reward: -2.15, score: -201.85968112630172, epsilon: 0.8456089354942221, total steps: 4630
episode:69, reward: -4.639799005550071, mean reward: -1.13, score: -203.12551754136268, epsilon: 0.8435657120732074, total steps: 4810
episode:70, reward: -0.36538874072552585, mean reward: -1.06, score: -199.98528852231584, epsilon: 0.8414372807622037, total steps: 4998
episode:71, reward: -5.383942342287809, mean reward: -6.26, score: -200.2692672106061, epsilon: 0.8410755635469467, total steps: 5030
episode:72, reward: -10.172043272049537, mean reward: -1.39, score: -200.2497855041321, epsilon: 0.8394498808060569, total steps: 5174
episode:73, reward: -3.1801711953654297, mean reward: -4.28, score: -201.0834439295537, epsilon: 0.8389199995090006, total steps: 5221
episode:74, reward: -11.035317751548773, mean reward: -10.85, score: -206.20887137007074, epsilon: 0.83870589313917, total steps: 5240
episode:75, reward: -7.03998848614367, mean reward: -1.37, score: -201.097839268672, epsilon: 0.8370513486433434, total steps: 5387
episode:76, reward: -8.306943402090242, mean reward: -7.8, score: -202.79453998987796, epsilon: 0.8367590695690356, total steps: 5413
episode:77, reward: -2.9034480096262074, mean reward: -3.73, score: -201.24580939533007, epsilon: 0.8361523751847176, total steps: 5467
episode:78, reward: -38.87074510146564, mean reward: -1.19, score: -235.0512373391984, epsilon: 0.8339318290050214, total steps: 5665
episode:79, reward: -11.929384839190911, mean reward: -8.95, score: -205.8946160485737, epsilon: 0.8336742937157485, total steps: 5688
episode:80, reward: -9.372687810013938, mean reward: -9.72, score: -204.10386910671056, epsilon: 0.8334392266894507, total steps: 5709
episode:81, reward: -2.279009058987504, mean reward: -1.31, score: -202.04434989781967, epsilon: 0.8317175549240835, total steps: 5863
episode:82, reward: -4.632244217635238, mean reward: -1.51, score: -203.89335497518664, epsilon: 0.8302114096036883, total steps: 5998
episode:83, reward: -9.365875265784677, mean reward: -6.32, score: -202.24843681548083, epsilon: 0.8298548230424364, total steps: 6030
episode:84, reward: -4.640544835711008, mean reward: -1.56, score: -202.92547322435001, epsilon: 0.8284078652477584, total steps: 6160
episode:85, reward: -6.545405555054867, mean reward: -3.08, score: -203.3633424156517, epsilon: 0.8276742837175912, total steps: 6226
episode:86, reward: -14.037365115957899, mean reward: -1.35, score: -210.1372560526753, epsilon: 0.825943110765946, total steps: 6382
episode:87, reward: -6.760458752846095, mean reward: -6.85, score: -205.52250193249233, epsilon: 0.8256106349683775, total steps: 6412
episode:88, reward: -1.78285696071831, mean reward: -1.81, score: -200.70993655974573, epsilon: 0.824381712721647, total steps: 6523
episode:89, reward: -6.38680519662078, mean reward: -6.68, score: -200.2780429612347, epsilon: 0.8240499059512957, total steps: 6553
episode:90, reward: -8.182798148231221, mean reward: -3.08, score: -206.39147927697613, epsilon: 0.8233093840618949, total steps: 6620
episode:91, reward: -2.850065415025258, mean reward: -7.5, score: -202.55529078428398, epsilon: 0.823011165102539, total steps: 6647
episode:92, reward: -7.73695022529602, mean reward: -8.4, score: -201.52623004140403, epsilon: 0.8227461781320089, total steps: 6671
episode:93, reward: -5.265536137228384, mean reward: -6.2, score: -204.46040398620372, epsilon: 0.8223819693611308, total steps: 6704
episode:94, reward: -1.0679817630772148, mean reward: -2.05, score: -206.82345940850814, epsilon: 0.8212683361196628, total steps: 6805
episode:95, reward: -1.5405801071347722, mean reward: -1.33, score: -201.5330763447286, epsilon: 0.8195953990074353, total steps: 6957
episode:96, reward: -6.622254069668723, mean reward: -6.85, score: -205.61068435162355, epsilon: 0.8192656430748934, total steps: 6987
episode:97, reward: -7.791948670069765, mean reward: -4.74, score: -203.69187331037637, epsilon: 0.8187932392901648, total steps: 7030
episode:98, reward: -6.757822100955038, mean reward: -6.85, score: -205.61750845203366, epsilon: 0.8184638270667018, total steps: 7060
episode:99, reward: -2.657596477100874, mean reward: -1.24, score: -202.2871657296452, epsilon: 0.8166764859384625, total steps: 7223
episode:100, reward: -7.134310929070529, mean reward: -7.92, score: -205.95654639873538, epsilon: 0.8163917732650265, total steps: 7249
episode:101, reward: -41.729153261686115, mean reward: -1.72, score: -239.73324020345598, epsilon: 0.8148714481376237, total steps: 7388
episode:102, reward: -4.39997267004491, mean reward: -5.17, score: -201.54015205785018, epsilon: 0.8144454241627886, total steps: 7427
episode:103, reward: -2.073188839083511, mean reward: -0.93, score: -210.38938461445002, epsilon: 0.8119704520181922, total steps: 7654
episode:104, reward: -6.211299248763881, mean reward: -6.72, score: -201.59154981707343, epsilon: 0.8116439632199242, total steps: 7684
episode:105, reward: 3.2609198702506936, mean reward: -0.93, score: -195.95128592115515, epsilon: 0.8093516073456798, total steps: 7895
episode:106, reward: -1.687147157931074, mean reward: -1.06, score: -203.61531835558813, epsilon: 0.8072716681575555, total steps: 8087
episode:107, reward: -5.409940779030074, mean reward: -6.11, score: -201.69082516315302, epsilon: 0.806914752793513, total steps: 8120
episode:108, reward: -3.6420151675188337, mean reward: -4.96, score: -203.44857413471357, epsilon: 0.80647154681844, total steps: 8161
episode:109, reward: -4.547252450718578, mean reward: -1.34, score: -203.6746272312447, epsilon: 0.8048307050183167, total steps: 8313
episode:110, reward: -11.047199078633264, mean reward: -11.21, score: -201.85553109517244, epsilon: 0.8046366306476576, total steps: 8331
episode:111, reward: 0.6554676598542291, mean reward: -0.95, score: -198.82730628183177, epsilon: 0.8023761132272331, total steps: 8541
episode:112, reward: -11.388464835458375, mean reward: -11.39, score: -204.97031148972047, epsilon: 0.8021826699561754, total steps: 8559
episode:113, reward: -10.181396636324548, mean reward: -6.83, score: -204.7958220194961, epsilon: 0.8018603750228986, total steps: 8589
episode:114, reward: -1.3223463908264497, mean reward: -2.64, score: -200.40609917809073, epsilon: 0.8010445124498424, total steps: 8665
episode:115, reward: 2.0688648324664554, mean reward: -0.94, score: -200.15480528843287, epsilon: 0.7987733614053956, total steps: 8877
episode:116, reward: -1.426184071989427, mean reward: -4.18, score: -200.81358897266585, epsilon: 0.7982600928126325, total steps: 8925
episode:117, reward: -9.798987113529344, mean reward: -6.52, score: -208.5837974618776, epsilon: 0.7979181092295501, total steps: 8957
episode:118, reward: -0.5971585555092781, mean reward: -1.89, score: -200.03626261271347, epsilon: 0.7967864045996208, total steps: 9063
episode:119, reward: -0.5772737038963691, mean reward: -1.26, score: -201.10177198434837, epsilon: 0.795081413549759, total steps: 9223
episode:120, reward: 2.8074026598205766, mean reward: -0.74, score: -196.3576884908015, epsilon: 0.7922660805839363, total steps: 9488
episode:121, reward: -0.9926544881842121, mean reward: -1.18, score: -198.9995460169513, epsilon: 0.7904867780076916, total steps: 9656
episode:122, reward: -7.366741763253603, mean reward: -7.6, score: -205.15888584515062, epsilon: 0.790201216755099, total steps: 9683
episode:123, reward: 5.909242908861133, mean reward: -0.66, score: -193.72376694964666, epsilon: 0.7870883611800993, total steps: 9978
episode:124, reward: -9.439644219390527, mean reward: -9.2, score: -202.44099484642908, epsilon: 0.7868567412373402, total steps: 10000
episode:125, reward: -2.3785911911730153, mean reward: -2.4, score: -201.27740106739634, epsilon: 0.7859730434725579, total steps: 10084
episode:126, reward: -6.203786910058407, mean reward: -4.47, score: -205.7065989555239, epsilon: 0.785489562919285, total steps: 10130
episode:127, reward: -11.421589507742931, mean reward: -11.39, score: -205.05123318749492, epsilon: 0.7853004613457787, total steps: 10148
episode:128, reward: -8.424889701760641, mean reward: -5.74, score: -206.726296011395, epsilon: 0.7849224040458678, total steps: 10184
episode:129, reward: -6.1329925498956905, mean reward: -9.12, score: -200.64327145323577, epsilon: 0.7846914647255332, total steps: 10206
episode:130, reward: -5.948540657766188, mean reward: -1.06, score: -201.116895554164, epsilon: 0.7827104733126339, total steps: 10395
episode:131, reward: -37.83877959653945, mean reward: -1.01, score: -234.62929013389646, epsilon: 0.7802860812414554, total steps: 10627
episode:132, reward: -5.992368471470491, mean reward: -3.2, score: -201.6852627453523, epsilon: 0.7796291194454911, total steps: 10690
episode:133, reward: -6.9091653942946625, mean reward: -4.69, score: -201.59559331059353, epsilon: 0.7791810563341627, total steps: 10733
episode:134, reward: -1.1309730499105162, mean reward: -3.14, score: -200.753460860334, epsilon: 0.7785146811862872, total steps: 10797
episode:135, reward: -4.529805476948772, mean reward: -5.75, score: -201.33897221173206, epsilon: 0.7781505148948537, total steps: 10832
episode:136, reward: -11.699665073510724, mean reward: -1.06, score: -209.74042323054627, epsilon: 0.7760937993074796, total steps: 11030
episode:137, reward: -9.51697290761443, mean reward: -6.25, score: -206.22951367806797, epsilon: 0.7757515786175925, total steps: 11063
episode:138, reward: -39.797907421265684, mean reward: -1.0, score: -238.84249843379092, epsilon: 0.7732675482619914, total steps: 11303
episode:139, reward: 0.5480193838729983, mean reward: -0.69, score: -196.98918468025923, epsilon: 0.770318512269275, total steps: 11589
episode:140, reward: 6.642915784543239, mean reward: -0.62, score: -192.86682054531312, epsilon: 0.7671048496787565, total steps: 11902
episode:141, reward: -9.25626952127234, mean reward: -8.86, score: -203.6867759638946, epsilon: 0.7668692682186499, total steps: 11925
episode:142, reward: -97.2751358287433, mean reward: -2.11, score: -132.630225207207, epsilon: 0.7662243761222267, total steps: 11988
episode:143, reward: -0.08573661652763565, mean reward: -1.21, score: -199.1562693501645, epsilon: 0.7645381211026792, total steps: 12153
episode:144, reward: -8.163256269500748, mean reward: -8.23, score: -205.77853456990505, epsilon: 0.7642829744811798, total steps: 12178
episode:145, reward: -10.161251230376957, mean reward: -10.33, score: -206.51021460842136, epsilon: 0.7640789227829586, total steps: 12198
episode:146, reward: -7.84511222419577, mean reward: -5.51, score: -203.73210005083132, epsilon: 0.763701580801511, total steps: 12235
episode:147, reward: -0.0755443670689373, mean reward: -1.14, score: -211.351806421628, epsilon: 0.7618076910261, total steps: 12421
episode:148, reward: 12.015429045792352, mean reward: -0.48, score: -187.74186641638315, epsilon: 0.7578731570349462, total steps: 12809
episode:149, reward: 1.8576140346979524, mean reward: -0.92, score: -197.72539999855786, epsilon: 0.7557023107017953, total steps: 13024
episode:150, reward: -1.3550401728723902, mean reward: -2.74, score: -200.00996605199086, epsilon: 0.7549667476166213, total steps: 13097
episode:151, reward: -1.6353687791243163, mean reward: -6.9, score: -200.05233423101032, epsilon: 0.7546747504533403, total steps: 13126
episode:152, reward: -37.15916663887823, mean reward: -1.19, score: -234.8062812200423, epsilon: 0.7526943823378464, total steps: 13323
episode:153, reward: 2.831910486706069, mean reward: -1.2, score: -206.01785825862092, epsilon: 0.7509798953227396, total steps: 13494
episode:154, reward: -101.61084697814452, mean reward: -2.73, score: -229.3698551987832, epsilon: 0.7501392239520553, total steps: 13578
episode:155, reward: 3.2258076538596816, mean reward: -0.73, score: -192.48960718418505, epsilon: 0.747493707633957, total steps: 13843
episode:156, reward: 0.530826969448321, mean reward: -0.99, score: -197.7864827170205, epsilon: 0.7455037126729707, total steps: 14043
episode:157, reward: -4.003280689780619, mean reward: -1.36, score: -203.3743342943925, epsilon: 0.7440149432541594, total steps: 14193
episode:158, reward: -1.6022800010876628, mean reward: -0.95, score: -204.19593816147943, epsilon: 0.7418767121110738, total steps: 14409
episode:159, reward: -6.104389128948905, mean reward: -1.94, score: -202.01010032813053, epsilon: 0.7408495442238823, total steps: 14513
episode:160, reward: -13.07363631332257, mean reward: -9.44, score: -207.7553784749612, epsilon: 0.7406324541973458, total steps: 14535
episode:161, reward: 0.291944662482976, mean reward: -0.76, score: -197.07788400697854, epsilon: 0.7380916654816418, total steps: 14793
episode:162, reward: -0.8968553952589353, mean reward: -5.0, score: -200.14114700044368, epsilon: 0.7376985825643249, total steps: 14833
episode:163, reward: -5.6424633961531825, mean reward: -9.67, score: -203.0365281072252, epsilon: 0.7374923039328973, total steps: 14854
episode:164, reward: -42.085385085057936, mean reward: -1.26, score: -240.20415540108564, epsilon: 0.7356189889741115, total steps: 15045
episode:165, reward: -6.1561428608388615, mean reward: -1.16, score: -224.4321211130825, epsilon: 0.7337312430643769, total steps: 15238
episode:166, reward: -13.549376484855568, mean reward: -9.31, score: -204.92783967453852, epsilon: 0.7335163898666848, total steps: 15260
episode:167, reward: 1.3131350762409655, mean reward: -0.85, score: -196.25149710927425, epsilon: 0.7312742358558875, total steps: 15490
episode:168, reward: -137.33747596752454, mean reward: -6.01, score: -150.18021028879863, epsilon: 0.7310309670722361, total steps: 15515
episode:169, reward: -2.681024803572254, mean reward: -1.29, score: -200.85016333340258, epsilon: 0.7295149308420136, total steps: 15671
episode:170, reward: 5.3067761737949155, mean reward: -0.71, score: -194.12512106198255, epsilon: 0.7268506447451814, total steps: 15946
episode:171, reward: -1.365238322544679, mean reward: -2.01, score: -201.2372016814522, epsilon: 0.7258844055878412, total steps: 16046
episode:172, reward: -3.3357644975636145, mean reward: -1.15, score: -209.17049121038667, epsilon: 0.7241293886439993, total steps: 16228
episode:173, reward: -4.650989232599742, mean reward: -2.59, score: -204.29623903324637, epsilon: 0.723369014625717, total steps: 16307
episode:174, reward: -3.2006306569789658, mean reward: -0.65, score: -199.47827327672428, epsilon: 0.7204031223680167, total steps: 16616
episode:175, reward: -5.608920919250098, mean reward: -8.84, score: -203.29177342096017, epsilon: 0.7201828832405053, total steps: 16639
episode:176, reward: -13.643338987210754, mean reward: -10.83, score: -205.72770088429803, epsilon: 0.720001001143027, total steps: 16658
episode:177, reward: -9.232858016820382, mean reward: -6.12, score: -202.08630402227578, epsilon: 0.7196852179686563, total steps: 16691
episode:178, reward: -5.4669338296530805, mean reward: -0.81, score: -200.92261810422798, epsilon: 0.7173168168414504, total steps: 16939
episode:179, reward: 2.3122968551291248, mean reward: -0.56, score: -194.64880382304273, epsilon: 0.7140359897805788, total steps: 17284
episode:180, reward: 2.5800881266339353, mean reward: -0.41, score: -193.25060048520862, epsilon: 0.7096112426567219, total steps: 17752
episode:181, reward: -1.6376547792638811, mean reward: -2.46, score: -201.5268552146597, epsilon: 0.7088390075984519, total steps: 17834
episode:182, reward: 2.0121911208179255, mean reward: -1.47, score: -197.42759376959037, epsilon: 0.7075790078826912, total steps: 17968
episode:183, reward: -12.10206451257386, mean reward: -8.46, score: -211.50309764400427, epsilon: 0.7073442001694635, total steps: 17993
episode:184, reward: -0.6815704133837263, mean reward: -1.16, score: -200.58933459668833, epsilon: 0.7057216267948846, total steps: 18166
episode:185, reward: 10.851254444724178, mean reward: -0.5, score: -188.29748434145455, epsilon: 0.7021809563086054, total steps: 18545
episode:186, reward: 1.6327673243880887, mean reward: -1.08, score: -198.03455538059399, epsilon: 0.7004689031933156, total steps: 18729
episode:187, reward: -6.087902653702327, mean reward: -2.77, score: -202.47514389513353, epsilon: 0.6997909106375498, total steps: 18802
episode:188, reward: 2.8292605632326917, mean reward: -0.71, score: -195.48405024464486, epsilon: 0.6972431684019018, total steps: 19077
episode:189, reward: -2.0925819336836105, mean reward: -1.24, score: -201.1401165034615, epsilon: 0.6957469947380505, total steps: 19239
episode:190, reward: -91.67228343164146, mean reward: -0.99, score: -291.11824520557826, epsilon: 0.6930405448833257, total steps: 19533
episode:191, reward: -135.02319477621094, mean reward: -6.97, score: -167.26394657084597, epsilon: 0.6928201116300827, total steps: 19557
episode:192, reward: 7.952510094687535, mean reward: -0.46, score: -191.3078856694003, epsilon: 0.6890477684729266, total steps: 19969
episode:193, reward: 18.368993792056227, mean reward: -0.38, score: -180.66190936928672, epsilon: 0.6847532555773536, total steps: 20441
episode:194, reward: -6.312486349255561, mean reward: -3.88, score: -205.66376809403252, epsilon: 0.6842728385789449, total steps: 20494
episode:195, reward: -1.3776060937441084, mean reward: -2.2, score: -200.39164435241725, epsilon: 0.6834488196171667, total steps: 20585
episode:196, reward: -4.478946074100147, mean reward: -8.5, score: -204.10611044286233, epsilon: 0.6832316743917496, total steps: 20609
episode:197, reward: 3.5256488703614135, mean reward: -0.75, score: -194.1950337616463, epsilon: 0.680902059148587, total steps: 20867
episode:198, reward: 16.229144308332497, mean reward: -0.31, score: -174.83636013715963, epsilon: 0.6757676941544829, total steps: 21439
episode:199, reward: -14.74104407258174, mean reward: -2.49, score: -206.85629610526598, epsilon: 0.6750261521753235, total steps: 21522
episode:200, reward: 0.5947827355240749, mean reward: -1.28, score: -198.97896340985722, epsilon: 0.6736436968359162, total steps: 21677
episode:201, reward: -10.414777590512905, mean reward: -7.19, score: -208.44221314439244, epsilon: 0.673385383672934, total steps: 21706
episode:202, reward: -0.45398568711094, mean reward: -1.05, score: -199.84957117893182, epsilon: 0.6716956319034958, total steps: 21896
episode:203, reward: -39.93079391939809, mean reward: -1.23, score: -238.13997002042592, epsilon: 0.669975032227358, total steps: 22090
episode:204, reward: -9.696022637920688, mean reward: -9.98, score: -209.61392026367363, epsilon: 0.6697890676137765, total steps: 22111
episode:205, reward: 24.099500327193855, mean reward: -0.34, score: -173.7148227926971, epsilon: 0.665298661298997, total steps: 22620
episode:206, reward: 8.436969034778068, mean reward: -0.48, score: -182.35111639336932, epsilon: 0.6619762608758829, total steps: 22999
episode:207, reward: 16.932659203609063, mean reward: -0.42, score: -186.6035807365068, epsilon: 0.6581416173129103, total steps: 23439
episode:208, reward: 5.050927555669051, mean reward: -0.58, score: -192.1416264233504, epsilon: 0.6552814111858084, total steps: 23769
episode:209, reward: -6.572094648292017, mean reward: -7.79, score: -202.5490757457029, epsilon: 0.6550566341228353, total steps: 23795
episode:210, reward: -88.08312677243688, mean reward: -0.86, score: -213.4982644471918, epsilon: 0.6529081846748103, total steps: 24044
episode:211, reward: -1.9132629891137984, mean reward: -0.7, score: -195.0719794331971, epsilon: 0.65052710510143, total steps: 24321
episode:212, reward: -92.20624654834558, mean reward: -1.67, score: -216.0284451009227, epsilon: 0.6494214385419877, total steps: 24450
episode:213, reward: -3.109313288347682, mean reward: -0.85, score: -202.70524182191375, epsilon: 0.6473868663835851, total steps: 24688
episode:214, reward: -98.6763386210878, mean reward: -2.75, score: -275.11458285954154, epsilon: 0.6465340658627289, total steps: 24788
episode:215, reward: 11.54233517694232, mean reward: -0.53, score: -192.52889031089913, epsilon: 0.6434570955741822, total steps: 25150
episode:216, reward: -84.6924444704372, mean reward: -0.83, score: -310.8094715257569, epsilon: 0.6402947944762348, total steps: 25524
episode:217, reward: -100.95362011034098, mean reward: -2.24, score: -136.49992971876912, epsilon: 0.6397806187929915, total steps: 25585
episode:218, reward: 1.7708430008729523, mean reward: -2.28, score: -198.05805516949437, epsilon: 0.6390480610648065, total steps: 25672
episode:219, reward: 0.6947787914501532, mean reward: -1.24, score: -199.0729232306857, epsilon: 0.6376948073626743, total steps: 25833
episode:220, reward: -35.199633385218036, mean reward: -1.34, score: -234.3379448884292, epsilon: 0.6362274053610413, total steps: 26008
episode:221, reward: -7.776132595778149, mean reward: -8.59, score: -206.04637099709493, epsilon: 0.6360264475596521, total steps: 26032
episode:222, reward: 18.917349889219565, mean reward: -0.4, score: -178.06663963732848, epsilon: 0.632287854553944, total steps: 26480
episode:223, reward: -100.03735090250626, mean reward: -4.09, score: -130.99929650066397, epsilon: 0.6320217266543025, total steps: 26512
episode:224, reward: -1.3460865471749208, mean reward: -6.09, score: -200.90885361737284, epsilon: 0.6317474096486829, total steps: 26545
episode:225, reward: -32.52423221018985, mean reward: -0.78, score: -231.85866967278395, epsilon: 0.6292678166140563, total steps: 26844
episode:226, reward: 16.248132517945553, mean reward: -0.33, score: -184.61994997459766, epsilon: 0.6246767897966456, total steps: 27401
episode:227, reward: 4.499187276126398, mean reward: -0.76, score: -196.40735221302174, epsilon: 0.622570773421246, total steps: 27658
episode:228, reward: -0.44963158152724736, mean reward: -2.53, score: -200.17342560533635, epsilon: 0.6219249509024964, total steps: 27737
episode:229, reward: -95.24877040617832, mean reward: -1.03, score: -284.2002075679469, epsilon: 0.6196825105587164, total steps: 28012
episode:230, reward: -8.611009713590942, mean reward: -9.1, score: -200.18078109394722, epsilon: 0.6195034956163624, total steps: 28034
episode:231, reward: -3.4287958394506477, mean reward: -0.97, score: -199.40899512455252, epsilon: 0.617829991835452, total steps: 28240
episode:232, reward: 15.16956868465693, mean reward: -0.41, score: -182.29427636569613, epsilon: 0.6142316651156222, total steps: 28685
episode:233, reward: -11.005113533858683, mean reward: 0.17, score: 112.2274868481019, epsilon: 0.6088010421398924, total steps: 29362
episode:234, reward: -33.87104712264799, mean reward: -0.77, score: -234.44802652079017, epsilon: 0.6063795110303579, total steps: 29666
episode:235, reward: -84.62144522542275, mean reward: -0.63, score: -244.97960398191165, epsilon: 0.6032962057236458, total steps: 30055
episode:236, reward: -4.702623811832864, mean reward: -6.31, score: -201.84058652036273, epsilon: 0.6030433281203139, total steps: 30087
episode:237, reward: -136.36961203124005, mean reward: -6.14, score: -153.45676931613855, epsilon: 0.6028458479124071, total steps: 30112
episode:238, reward: -2.312704611759262, mean reward: -0.91, score: -200.5746227676721, epsilon: 0.6011031869548715, total steps: 30333
episode:239, reward: -99.20287900148325, mean reward: -2.46, score: -167.1029714134561, epsilon: 0.6005680895198066, total steps: 30401
episode:240, reward: 9.455581669858221, mean reward: -0.67, score: -190.20820351308055, epsilon: 0.5983467147625045, total steps: 30684
episode:241, reward: -108.75019888823456, mean reward: -1.9, score: -185.97662731479505, epsilon: 0.597579566490928, total steps: 30782
episode:242, reward: -6.61200701877046, mean reward: -10.67, score: -202.75143137793037, epsilon: 0.5974309579206702, total steps: 30801
episode:243, reward: -98.33384330344795, mean reward: -2.13, score: -229.98200836501945, epsilon: 0.5965870013766257, total steps: 30909
episode:244, reward: -0.596253132822671, mean reward: -0.5, score: -185.84488897037355, epsilon: 0.5937055207055874, total steps: 31279
episode:245, reward: 9.760464222336221, mean reward: -0.5, score: -186.15424305089195, epsilon: 0.5908392305364026, total steps: 31649
episode:246, reward: -21.99934689061103, mean reward: -0.1, score: -63.61108950539795, epsilon: 0.5858633618372332, total steps: 32296
episode:247, reward: -1.2232599639760888, mean reward: -0.98, score: -199.95434481397632, epsilon: 0.5843039762482573, total steps: 32500
episode:248, reward: -4.146563611114987, mean reward: -6.26, score: -200.2338267478677, epsilon: 0.5840597788227795, total steps: 32532
episode:249, reward: -26.052446020120197, mean reward: -0.56, score: -225.11514704262598, epsilon: 0.5810015397275305, total steps: 32934
episode:250, reward: 16.302234755332684, mean reward: -0.43, score: -179.39767527067565, epsilon: 0.577840150361175, total steps: 33352
episode:251, reward: -94.26848751977548, mean reward: -1.24, score: -126.5739023031997, epsilon: 0.5770715719566206, total steps: 33454
episode:252, reward: 24.483369874052087, mean reward: -0.33, score: -166.017493432881, epsilon: 0.5733127128116488, total steps: 33955
episode:253, reward: -4.421128765176957, mean reward: -6.3, score: -201.54050608267949, epsilon: 0.573073538815442, total steps: 33987
episode:254, reward: 9.902505496359854, mean reward: -0.45, score: -187.23713829010538, epsilon: 0.5699964911530323, total steps: 34400
episode:255, reward: 4.672616854212747, mean reward: -0.68, score: -196.34930421939097, epsilon: 0.5678688701428174, total steps: 34687
episode:256, reward: 22.020115200630325, mean reward: -0.43, score: -177.68820304295267, epsilon: 0.5648371490389045, total steps: 35098
episode:257, reward: -37.21645032124383, mean reward: -0.84, score: -232.37921887407958, epsilon: 0.5627965647749515, total steps: 35376
episode:258, reward: -95.87694519574556, mean reward: -1.34, score: -114.82099196776866, epsilon: 0.5621669444127884, total steps: 35462
episode:259, reward: 18.204444300726614, mean reward: -0.28, score: -170.5562498669919, epsilon: 0.5577957026878858, total steps: 36062
episode:260, reward: 31.681756546115032, mean reward: -0.32, score: -166.84108308696088, epsilon: 0.5540230815606629, total steps: 36584
episode:261, reward: -6.371525780106196, mean reward: -5.96, score: -202.711177660833, epsilon: 0.5537783297941455, total steps: 36618
episode:262, reward: 2.2054725674074662, mean reward: -0.78, score: -193.22848107174778, epsilon: 0.5520038445134803, total steps: 36865
episode:263, reward: -9.982278264648377, mean reward: -9.56, score: -200.79712076439674, epsilon: 0.5518532659480403, total steps: 36886
episode:264, reward: -57.73616424028007, mean reward: -0.26, score: -149.04985193762343, epsilon: 0.5477762282606059, total steps: 37457
episode:265, reward: -0.806639841002211, mean reward: -0.15, score: -150.06309070525336, epsilon: 0.5407086815916368, total steps: 38458
episode:266, reward: -20.286288074167704, mean reward: -0.5, score: -219.8301884518376, epsilon: 0.5376547997859281, total steps: 38895
episode:267, reward: -2.2313960356257416, mean reward: -1.07, score: -202.10836202547713, epsilon: 0.5363399077295791, total steps: 39084
episode:268, reward: -12.61676812951569, mean reward: -8.62, score: -206.81096224886485, epsilon: 0.5361731911999671, total steps: 39108
episode:269, reward: 0.5932175371792283, mean reward: -1.06, score: -195.0073444737971, epsilon: 0.5348969283491235, total steps: 39292
episode:270, reward: -3.004929700679334, mean reward: -0.43, score: -200.50961962464842, epsilon: 0.5317140280609016, total steps: 39753
episode:271, reward: -98.84433385853228, mean reward: -3.91, score: -187.51176296596873, epsilon: 0.5313838230963006, total steps: 39801
episode:272, reward: -5.982353006515481, mean reward: -0.43, score: -186.2883668706694, epsilon: 0.5284289801583597, total steps: 40232
episode:273, reward: -117.00088637864539, mean reward: -0.59, score: -213.71557450135163, epsilon: 0.5259612053213971, total steps: 40594
episode:274, reward: -100, mean reward: -4.42, score: -106.13094673658078, epsilon: 0.5257980465940956, total steps: 40618
episode:275, reward: 20.0453286365197, mean reward: -0.27, score: -179.19721380457696, epsilon: 0.5212993677099148, total steps: 41283
episode:276, reward: -91.53982951151903, mean reward: -0.77, score: -93.4303042599522, epsilon: 0.5204853967946976, total steps: 41404
episode:277, reward: -3.409538794583101, mean reward: -8.37, score: -200.86215228057222, epsilon: 0.5203241151656557, total steps: 41428
episode:278, reward: -95.52621348062232, mean reward: -1.45, score: -275.56844968059363, epsilon: 0.5190492520927871, total steps: 41618
episode:279, reward: -31.7015039323657, mean reward: -1.04, score: -238.2685776322922, epsilon: 0.5175172981732733, total steps: 41847
episode:280, reward: 25.591903811635525, mean reward: -0.31, score: -166.99006658006795, epsilon: 0.5139047294240787, total steps: 42390
episode:281, reward: -94.23053987599302, mean reward: -1.37, score: -204.18609318997636, epsilon: 0.5129183252597429, total steps: 42539
episode:282, reward: -2.892358532812459, mean reward: -0.61, score: -192.10637727592265, epsilon: 0.5108267061560344, total steps: 42856
episode:283, reward: -7.366268093075452, mean reward: -5.3, score: -206.55179019770316, epsilon: 0.5105700313572238, total steps: 42895
episode:284, reward: -122.8043416059288, mean reward: -0.68, score: -230.67861935479283, epsilon: 0.5083449487185407, total steps: 43234
episode:285, reward: -10.908646248535094, mean reward: -1.06, score: -212.92210254895028, epsilon: 0.5070372607374728, total steps: 43434
episode:286, reward: -3.993327519231648, mean reward: -5.57, score: -200.63799176779418, epsilon: 0.5068022734338652, total steps: 43470
episode:287, reward: -81.86026296576554, mean reward: 0.06, score: 10.490411387709798, epsilon: 0.5056226390257158, total steps: 43651
episode:288, reward: 64.9264367324973, mean reward: -0.3, score: -133.10579337059738, epsilon: 0.5027289003396039, total steps: 44097
episode:289, reward: -3.718900891211615, mean reward: -5.96, score: -202.53642363990073, epsilon: 0.5025090568400397, total steps: 44131
episode:290, reward: -91.21582674593432, mean reward: -0.63, score: -133.287001597614, epsilon: 0.5011471189206335, total steps: 44342
episode:291, reward: 75.43077646863283, mean reward: -0.25, score: -128.30616611677107, epsilon: 0.4978017603204821, total steps: 44863
episode:292, reward: 13.442758366065167, mean reward: -0.39, score: -185.02983643600197, epsilon: 0.4947860999525963, total steps: 45336
episode:293, reward: -4.674205031085081, mean reward: -5.51, score: -204.02777486167136, epsilon: 0.4945510608512847, total steps: 45373
episode:294, reward: -99.26763262560829, mean reward: -2.19, score: -280.57298795987435, epsilon: 0.4937389102468636, total steps: 45501
episode:295, reward: 25.921657610380567, mean reward: -0.27, score: -167.59458037226764, epsilon: 0.4898699902857615, total steps: 46114
episode:296, reward: -12.596891641885, mean reward: -9.54, score: -209.87106849990573, epsilon: 0.4897317671535874, total steps: 46136
episode:297, reward: -95.34156328225458, mean reward: -0.38, score: -22.540705583755212, epsilon: 0.48936129224334535, total steps: 46195
episode:298, reward: -91.5230674425506, mean reward: -1.15, score: -223.07307931796106, epsilon: 0.4881453195738466, total steps: 46389
episode:299, reward: 28.57137631898708, mean reward: -0.33, score: -170.07272780589773, epsilon: 0.48492122420731265, total steps: 46906
episode:300, reward: -92.93193288856051, mean reward: -1.12, score: -119.09723323633037, epsilon: 0.48426312760954887, total steps: 47012
episode:301, reward: 16.907202089037618, mean reward: -0.38, score: -181.69117880132606, epsilon: 0.4813448033565003, total steps: 47484
episode:302, reward: 5.324901193126744, mean reward: -0.95, score: -194.24267342727816, epsilon: 0.4800834272061242, total steps: 47689
episode:303, reward: -99.57265347385659, mean reward: -1.61, score: -132.3339382890511, epsilon: 0.4795799101660995, total steps: 47771
episode:304, reward: -97.44951943980888, mean reward: -2.77, score: -246.2651149105163, epsilon: 0.4790340770620341, total steps: 47860
episode:305, reward: 17.1607201562644, mean reward: -0.4, score: -182.9536830962507, epsilon: 0.4762604886926877, total steps: 48314
episode:306, reward: -90.23770349394587, mean reward: -0.96, score: -81.0077059969299, epsilon: 0.47574928289108215, total steps: 48398
episode:307, reward: -97.58372546484716, mean reward: -1.85, score: -143.99665661915142, epsilon: 0.47527514076124927, total steps: 48476
episode:308, reward: -69.15163064004057, mean reward: -0.4, score: -192.0477543111776, epsilon: 0.4723568763469456, total steps: 48958
episode:309, reward: -45.576485359668624, mean reward: 0.01, score: 3.057175438354264, epsilon: 0.4696204596394502, total steps: 49413
episode:310, reward: -123.4709236553439, mean reward: -0.72, score: -107.85781873902827, epsilon: 0.4687222356667588, total steps: 49563
episode:311, reward: 21.10898779238793, mean reward: -0.43, score: -178.08081686562653, epsilon: 0.4662352624734382, total steps: 49980
episode:312, reward: -89.65176502764777, mean reward: -0.25, score: -27.723789084567997, epsilon: 0.4655876290673123, total steps: 50089
episode:313, reward: -23.025259703000316, mean reward: 0.25, score: 93.43150403015255, epsilon: 0.4633790302650842, total steps: 50462
episode:314, reward: -41.357134066348806, mean reward: -0.74, score: -241.64095115128586, epsilon: 0.46145246306630355, total steps: 50789
episode:315, reward: -5.224123029990959, mean reward: -1.22, score: -202.91734136992812, epsilon: 0.4604778889627643, total steps: 50955
episode:316, reward: -36.02447715744824, mean reward: 0.61, score: 151.30815309106964, epsilon: 0.4590203543383452, total steps: 51204
episode:317, reward: 20.457022811378536, mean reward: -0.4, score: -178.78541249287224, epsilon: 0.4564109829656207, total steps: 51652
episode:318, reward: -7.794465078676607, mean reward: -6.39, score: -204.32292591015667, epsilon: 0.456225237547024, total steps: 51684
episode:319, reward: -100, mean reward: -3.83, score: -172.34649448852403, epsilon: 0.4559641766728725, total steps: 51729
episode:320, reward: 53.883583904633724, mean reward: -0.45, score: -145.48240321223923, epsilon: 0.4541125758915663, total steps: 52049
episode:321, reward: -97.19163625396484, mean reward: -1.47, score: -120.90393062444193, epsilon: 0.45363946403656763, total steps: 52131
episode:322, reward: 11.048873152793476, mean reward: -0.58, score: -184.17514203374955, epsilon: 0.45179846625912484, total steps: 52451
episode:323, reward: -1.0899739792293364, mean reward: -1.43, score: -200.3255992333736, epsilon: 0.4509956723880756, total steps: 52591
episode:324, reward: -94.40593209884025, mean reward: -1.09, score: -82.7497533374182, epsilon: 0.45056054191448336, total steps: 52667
episode:325, reward: 14.063855336994934, mean reward: 0.15, score: 137.85743822676744, epsilon: 0.445279651285723, total steps: 53596
episode:326, reward: 12.16600106052524, mean reward: -0.52, score: -182.84661091255046, epsilon: 0.44331380452872843, total steps: 53945
episode:327, reward: -92.61377808506302, mean reward: -1.21, score: -156.35239149847985, epsilon: 0.44258965083551427, total steps: 54074
episode:328, reward: -9.201191139930227, mean reward: -7.17, score: -207.84557698960882, epsilon: 0.4424270402375463, total steps: 54103
episode:329, reward: 14.630354932572128, mean reward: -0.42, score: -183.498647493342, epsilon: 0.44000709096226714, total steps: 54536
episode:330, reward: -3.2401448237365558, mean reward: -8.41, score: -201.84722650365353, epsilon: 0.439873397165612, total steps: 54560
episode:331, reward: -91.55108174008883, mean reward: -1.02, score: -119.15681192883754, epsilon: 0.4392222959165451, total steps: 54677
episode:332, reward: 3.659240023174269, mean reward: 0.61, score: 608.5400717775939, epsilon: 0.43369602410038016, total steps: 55678
episode:333, reward: -99.74936310306225, mean reward: -1.51, score: -145.19489434723116, epsilon: 0.4331701730761639, total steps: 55774
episode:334, reward: 25.691919704991864, mean reward: -0.27, score: -177.62779269700306, epsilon: 0.42965032632427536, total steps: 56420
episode:335, reward: -4.91818525868878, mean reward: 0.06, score: 43.66892050656669, epsilon: 0.4257975754286279, total steps: 57134
episode:336, reward: -86.26035372208992, mean reward: -0.71, score: -108.84419036882585, epsilon: 0.42497172952626866, total steps: 57288
episode:337, reward: -72.21955839899104, mean reward: -0.26, score: -102.68220441815922, epsilon: 0.422877756437816, total steps: 57680
episode:338, reward: -25.411634961793958, mean reward: -0.59, score: -222.5997582922182, epsilon: 0.4208696433381334, total steps: 58058
episode:339, reward: -8.02807445359554, mean reward: -9.33, score: -205.27538097823063, epsilon: 0.42075310262187043, total steps: 58080
episode:340, reward: -86.01452181283835, mean reward: -0.28, score: -51.36345145270024, epsilon: 0.41978511393296847, total steps: 58263
episode:341, reward: -87.17694331419949, mean reward: -0.45, score: -68.71521568687639, epsilon: 0.4189724809064071, total steps: 58417
episode:342, reward: 4.800897260509952, mean reward: -0.7, score: -195.01901684248844, epsilon: 0.41750478886176684, total steps: 58696
episode:343, reward: -66.87741231115484, mean reward: -0.44, score: -249.84254643617882, epsilon: 0.4145191933178749, total steps: 59267
episode:344, reward: -75.07286526538248, mean reward: -0.13, score: -52.769857817598805, epsilon: 0.41247323431585947, total steps: 59661
episode:345, reward: -182.1035466067671, mean reward: -0.79, score: -217.5850766145233, epsilon: 0.4110571837342639, total steps: 59935
episode:346, reward: -1.484575863925361, mean reward: -0.61, score: -198.23556067863765, epsilon: 0.40937959825971276, total steps: 60261
episode:347, reward: -3.028748730863046, mean reward: -3.35, score: -207.49527627911104, epsilon: 0.40906143153874475, total steps: 60323
episode:348, reward: 26.955404180619077, mean reward: -0.28, score: -169.27253858391848, epsilon: 0.4059358917203803, total steps: 60935
episode:349, reward: -15.575738411790137, mean reward: -1.9, score: -208.7085235944348, epsilon: 0.40537700313229114, total steps: 61045
episode:350, reward: -94.72735016407498, mean reward: -0.44, score: -33.3243025198288, epsilon: 0.40499137462224805, total steps: 61121
episode:351, reward: 40.92687266336965, mean reward: -0.35, score: -158.4492879563429, epsilon: 0.40269645214286603, total steps: 61575
episode:352, reward: 28.63044372319156, mean reward: -0.24, score: -171.19296938984684, epsilon: 0.3991421712143478, total steps: 62284
episode:353, reward: -2.3847738689338627, mean reward: 0.11, score: 90.59021190495336, epsilon: 0.3950908715189116, total steps: 63101
episode:354, reward: 18.586156092660644, mean reward: -0.36, score: -179.97802906150602, epsilon: 0.3926249297143986, total steps: 63603
episode:355, reward: 24.603100192782343, mean reward: -0.3, score: -171.74597879538956, epsilon: 0.38982203828469036, total steps: 64178
episode:356, reward: 19.625907621262307, mean reward: -0.35, score: -167.07392033302426, epsilon: 0.38753837468767816, total steps: 64650
episode:357, reward: -66.45033017653157, mean reward: -0.02, score: -7.576791125115697, epsilon: 0.3858261086919422, total steps: 65006
episode:358, reward: -97.6253578684514, mean reward: -3.31, score: -122.495719924512, epsilon: 0.38564864751050615, total steps: 65043
episode:359, reward: 5.446846217366355, mean reward: -0.41, score: -193.50658214071754, epsilon: 0.3834025554814372, total steps: 65513
episode:360, reward: 7.902263103354777, mean reward: -0.66, score: -191.72632625531634, epsilon: 0.382024173514264, total steps: 65803
episode:361, reward: -71.1883025946959, mean reward: -0.22, score: -97.37129343133395, epsilon: 0.37994370987357395, total steps: 66243
episode:362, reward: -75.30238335341707, mean reward: -0.05, score: -17.40469021113779, epsilon: 0.3783403212257765, total steps: 66584
episode:363, reward: 11.550149911251884, mean reward: -0.48, score: -187.11887087709218, epsilon: 0.37651141862180615, total steps: 66975
episode:364, reward: -68.52447643736741, mean reward: -0.09, score: -50.267783054522376, epsilon: 0.3738912392319301, total steps: 67539
episode:365, reward: -97.51481139897066, mean reward: -1.31, score: -126.9854030061865, epsilon: 0.37344272933976036, total steps: 67636
episode:366, reward: -4.453852845851207, mean reward: -1.95, score: -202.8137973833414, epsilon: 0.37296254265460704, total steps: 67740
episode:367, reward: -94.97694223374535, mean reward: -1.46, score: -96.317767250712, epsilon: 0.3726581786228383, total steps: 67806
episode:368, reward: -93.31121636133442, mean reward: -1.24, score: -271.09363024769294, epsilon: 0.37165489193813805, total steps: 68024
episode:369, reward: 27.477366916176074, mean reward: -0.39, score: -162.88753610381994, epsilon: 0.36974444385200583, total steps: 68441
episode:370, reward: -128.7821342854358, mean reward: -0.89, score: -141.1311175197152, epsilon: 0.36901899140529976, total steps: 68600
episode:371, reward: -168.3418974176059, mean reward: -1.08, score: -283.29582210826914, epsilon: 0.36782718067460185, total steps: 68862
episode:372, reward: -1.8347998450583716, mean reward: -1.43, score: -200.7036122614833, epsilon: 0.3671921615440562, total steps: 69002
episode:373, reward: -17.16403721378485, mean reward: -0.13, score: -88.57044999493806, epsilon: 0.36422452496910945, total steps: 69660
episode:374, reward: -61.12488535046727, mean reward: 0.46, score: 303.397837213931, epsilon: 0.36128020658577414, total steps: 70319
episode:375, reward: -100.13765314749423, mean reward: -3.53, score: -137.8405180817472, epsilon: 0.36110682734509253, total steps: 70358
episode:376, reward: 43.4812365153093, mean reward: -0.17, score: -154.0518425013838, epsilon: 0.35707983973379, total steps: 71270
episode:377, reward: 42.183586039109464, mean reward: -0.29, score: -154.68759273146105, epsilon: 0.3547287582661317, total steps: 71808
episode:378, reward: -6.7378315703589955, mean reward: 0.75, score: 498.0523763179521, epsilon: 0.351834606460525, total steps: 72476
episode:379, reward: -61.15808013267264, mean reward: 0.1, score: 45.79225639180109, epsilon: 0.3498576248150585, total steps: 72936
episode:380, reward: 14.843744090795548, mean reward: -0.44, score: -182.0125110105105, epsilon: 0.34809793211312406, total steps: 73348
episode:381, reward: -93.13654909459615, mean reward: -1.62, score: -139.31884282083817, epsilon: 0.34773192239139455, total steps: 73434
episode:382, reward: -62.4094931577045, mean reward: 0.49, score: 151.57195559571687, epsilon: 0.3464290144254858, total steps: 73741
episode:383, reward: -0.15310621943429226, mean reward: 1.23, score: 758.4892757896906, epsilon: 0.34383608086422224, total steps: 74356
episode:384, reward: -172.13331491008174, mean reward: -0.38, score: -271.77302205544925, epsilon: 0.34087080706848116, total steps: 75066
episode:385, reward: -21.93844462588433, mean reward: 0.24, score: 144.18878231844127, epsilon: 0.33842536418611563, total steps: 75657
episode:386, reward: -63.479733884458064, mean reward: -0.08, score: -36.07622474584262, epsilon: 0.3365157453801417, total steps: 76122
episode:387, reward: -134.41616669394926, mean reward: -4.34, score: -117.28197144751272, epsilon: 0.33640525347458955, total steps: 76149
episode:388, reward: -78.61414003274966, mean reward: -0.01, score: -3.3337939470016096, epsilon: 0.3354575959059343, total steps: 76381
episode:389, reward: -97.16480642381795, mean reward: -0.88, score: -151.2219961467199, epsilon: 0.3347611148270391, total steps: 76552
episode:390, reward: 9.812259518371066, mean reward: -0.7, score: -194.5565308216306, epsilon: 0.33364055299075435, total steps: 76828
episode:391, reward: -76.55820468899636, mean reward: -0.45, score: -223.10021031012042, epsilon: 0.33164993115692154, total steps: 77321
episode:392, reward: 5.890613370298028, mean reward: -0.63, score: -189.68803022971565, epsilon: 0.3304414365783788, total steps: 77622
episode:393, reward: -96.54122373354235, mean reward: -1.11, score: -81.3510625010552, epsilon: 0.3301491286672781, total steps: 77695
episode:390, reward: -75.568684094858, mean reward: 0.29, score: 66.51006259992816, epsilon: 0.33270608189123146, total steps: 77059
episode:391, reward: 16.820708975705106, mean reward: -0.35, score: -176.084231086496, epsilon: 0.33070597748255276, total steps: 77556
episode:392, reward: -135.16953884372603, mean reward: -2.03, score: -201.06791674872187, epsilon: 0.33030925963100594, total steps: 77655
episode:393, reward: 7.9190827459658095, mean reward: -0.48, score: -194.56888143031847, epsilon: 0.3286762281019621, total steps: 78064
episode:394, reward: 65.96132379050643, mean reward: -0.19, score: -139.5765866973797, epsilon: 0.32581665444454627, total steps: 78786
